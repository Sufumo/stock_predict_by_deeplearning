

# **PINN-MTICG 模型高保真复现与架构深度重构报告**

## **I. 引言：量化金融中的多模态深度学习范式**

### **A. PINN-MTICG模型的战略定位与核心创新**

PINN信息约束与时序截面双流网络模型（PINN-MTICG）代表了量化金融选股模型中的一个重要进步，它旨在通过多模态集成来应对金融时间序列固有的高非线性、非平稳性和复杂关联性问题 1。该模型创新性地融合了三个核心技术范式：Transformer架构用于时序特征提取、图注意力网络（GAT）用于截面关联建模，以及物理信息神经网络（PINN）用于引入宏观经济约束 1。

传统深度学习模型在股票预测中通常难以有效整合不同频率和类型的数据（如高频量价数据与低频宏观指标）。PINN-MTICG模型的核心创新在于其“自上而下”与“自下而上”的结合方法 1。具体而言，它将宏观经济状态方程转化为可计算的软约束，通过PINN损失项嵌入微观因子挖掘模型中，从而实现了宏观信息对个股收益预测的有效信息映射 1。这种结构上的优势，使其能够解析复杂的市场动力学，并在回测中取得了显著的业绩，例如因子月平均IC（信息系数）达到11.41%，多头组合年化收益达到37.51% 1。

### **B. 报告方法论：基于性能指标的架构推导**

鉴于原始研究报告中未能明确给出双流网络的最终解码方式和完整的损失函数数学形式 1，本报告将采用基于高性能指标的反向推导方法论。预测模型的成功在很大程度上依赖于其输出与真实目标（未来收益率）之间的优化函数和映射机制。因此，基于原模型所展示的优秀因子区分度（高IC）和超额收益率 1，本报告推导出的架构和解码方案必须是理论上最能支撑此类稳健结果的结构。

### **C. Transformer和GAT在金融场景中的应用基础**

Transformer模型因其自注意力机制（Self-Attention Mechanism）在处理复杂时间序列问题时表现出的显著优势，已成为金融时间序列预测的新方法 2。自注意力机制能够自适应地捕捉序列中的长期依赖关系，优于传统的循环神经网络（RNN）结构。例如，Informer 2 等改进型Transformer模型通过引入ProbSparse Self-Attention等高效机制，提高了对长序列数据的处理能力 2。

同时，GAT（Graph Attention Networks）被用于处理股票之间的截面关联。GAT能够通过可学习的注意力权重，动态地聚合相邻节点（股票）的信息，从而有效建模行业拓扑结构和资金传导效应中复杂的非线性关联 1。值得注意的是，Transformer本身被认为是图注意力网络（GAT）的一种特殊形式 3，它们在深层架构中都面临过平滑（over-smoothing）现象，即表达能力随着层数的增加而指数退化 3。在PINN-MTICG中，两者被巧妙地分离用于处理时间和截面维度，最大限度地发挥各自的优势。

## **II. 时序编码流：多尺度Transformer (Multi-Transformer) 架构的深度解析**

### **A. 输入特征工程与数据规范**

时序编码流的首要任务是捕捉个股量价数据的长期时序依赖 1。模型输入基于个股的基本量价信息构建了14个时序量价特征 1。在实际复现中，这些特征通常包括：短期收益率、交易量变化率、波动率指标（如ATR）、换手率以及各种动量和反转信号。

由于股票数据存在巨大的量纲差异和截面异质性（例如，高价股与低价股、高换手率股与低换手率股），为了确保Transformer的自注意力机制能够有效地在不同股票之间进行特征比较，\*\*跨截面标准化（Cross-sectional Normalization）\*\*是特征工程的关键步骤。通过将同一交易日所有股票的某一特征进行Z-score标准化或Rank标准化，可以有效消除截面差异对注意力计算的干扰。

### **B. Multi-Transformer Encoder架构与多尺度设计**

PINN-MTICG模型采用多尺度设计来提取时序特征。它在20日、40日及80日三个不同的尺度下，分别利用独立的Transformer编码器进行时序信息处理 1。

#### **1\. 多尺度对抗非平稳性**

金融时间序列的预测信号具有多频特性，其强度和持续性高度依赖于观察的时间窗口。例如，短周期（20日）可能捕捉市场瞬时动量或情绪，而长周期（80日）则可能反映基本面或长期趋势。单一固定长度的Transformer编码器容易在捕捉市场噪音或受限于固定窗口内的局部信息。这种多尺度设计允许模型并行学习不同频率分量上的特征表示，这与 TimesNet 2 等先进的时序模型解决非平稳性的思路相吻合。通过整合多尺度的信息，模型能够提升特征的鲁棒性，避免在某一固定时间窗口内发生过拟合。

#### **2\. Transformer编码器结构**

每个尺度的Transformer编码器（例如 $E\_{20}, E\_{40}, E\_{80}$）均由多层结构组成，每层包含多头自注意力机制和前馈神经网络 2。编码器的输入是过去 $T\_{scale}$ 日的14维特征序列，输出是该尺度下个股的特征表示 $\\mathbf{F}\_{scale}$，该特征向量将时间序列信息压缩为定长的、具有自适应时间戳特征的表示 1。

### **C. 关键组件重构：门控融合层 (Gated Fusion Layer)**

门控融合层是Multi-Transformer架构的连接核心，其功能是对三个不同尺度的编码器输出 $\\mathbf{F}\_{20}, \\mathbf{F}\_{40}, \\mathbf{F}\_{80}$ 进行加权融合，完成时序特征的编码 $\\mathbf{F}\_{TS}$ 1。

#### **1\. 动态加权机制的必要性**

简单的特征拼接（Concatenation）或平均（Averaging）是一种固定参数的融合方式，无法根据市场状态动态调整不同尺度的重要性。由于金融市场状态（如牛市、熊市、震荡市）的波动性和趋势持续时间不同，在某些时期，短期动量信息可能更具预测价值；而在另一些时期，长周期趋势可能更稳定。因此，门控机制必须学习动态权重，以反映当前市场状态下最具预测价值的时间尺度。

#### **2\. 最有可能的实现方案推导**

最稳健且可学习的实现方案是引入一个小型神经网络 $\\mathcal{G}$ 来计算动态权重。这个网络将所有尺度的特征拼接后作为输入，输出一个经过Softmax归一化的权重向量 $\\mathbf{W}\_{scale}$：

$$\\mathbf{W}\_{scale} \= \[w\_{20}, w\_{40}, w\_{80}\] \= \\text{Softmax}(\\mathcal{G}(\\text{Concat}(\\mathbf{F}\_{20}, \\mathbf{F}\_{40}, \\mathbf{F}\_{80})))$$  
最终的时序特征表示 $\\mathbf{F}\_{TS}$ 是这三个尺度特征的加权和：

$$\\mathbf{F}\_{TS} \= w\_{20} \\mathbf{F}\_{20} \+ w\_{40} \\mathbf{F}\_{40} \+ w\_{80} \\mathbf{F}\_{80}$$  
这种门控加权方式允许模型根据输入数据自动调整对长/短周期信息的依赖，避免了固定融合参数可能导致的次优结果，从而提升了模型在不同市场周期中的泛化能力。

## **III. 截面关联流：基于图注意力网络 (GAT) 的拓扑结构建模**

### **A. 金融图结构构建的底层逻辑与双图机制**

截面关联流的目的是解析股票间的非线性关联与风险传导路径，将传统的“分散化”原则转化为可量化的图结构学习问题 1。PINN-MTICG通过构建**时序截面双流网络**来整合信息 1。为了捕捉全面的市场关联，该流构建了两种关键的图结构：

1. **行业关联图（结构图）：** 基于申万一级行业分类构建，并引入额外的跨行业边 1。这种跨行业边的设计至关重要。它不仅关注传统行业分类内部的结构关联，还旨在捕捉产业链上下游、或受共同主题驱动（如“数字经济”、“新能源”等）的跨行业股票间的结构性关联。这使得GAT能够有效地捕捉结构性关联。  
2. **资金流向图（动态图）：** 基于部分资金流特征的相似性构建资金流向相似边 1。资金流向图捕捉了短期内由市场情绪、交易行为或机构操作引发的**共振效应**和风险传导。由于资金流瞬息万变，该图结构必须每日或高频更新，通常使用特征的余弦相似度或皮尔逊相关系数来动态构建连接。

### **B. indcap-GAT模型的配置与信息传递**

模型使用图注意力网络（GAT）对上述双图结构进行处理，完成截面关联信息的编码 $\\mathbf{F}\_{CS}$ 1。

#### **1\. GAT的选择优势**

GAT的优势在于它能够为相邻节点（即相关联的股票）分配可学习的注意力权重。在聚合邻居信息时，GAT动态地衡量每只股票对目标股票信息传导的重要性 1。这比固定权重的图卷积网络（GCN）更适合处理多变且复杂的金融市场关联和风险传导。

#### **2\. 关键连接假设：信息流层次结构**

GAT的节点特征 $\\mathbf{X}\_{node}$ 的选择是连接双流网络的关键。最合理的假设是，GAT的节点特征输入**直接采用 Multi-Transformer 的输出 $\\mathbf{F}\_{TS}$**。

这种连接模式建立了一个清晰的信息流层次：首先，Transformer在时间维度上为每只股票提取了高度特异性的、多尺度的因子表示 $\\mathbf{F}\_{TS}$；随后，GAT在截面维度上，利用 $\\mathbf{F}\_{TS}$ 作为节点特征，基于行业和资金流图结构进行信息扩散和关联建模。最终GAT输出的特征 $\\mathbf{F}\_{CS}$ 包含了\*\*“由时间维度编码、在截面上传导”\*\*的复杂中观信息。这种结构保证了截面关联分析是在具有时间深度信息的特征空间上进行的，而非简单的原始量价输入。

## **IV. PINN信息约束：宏观状态方程与物理损失项的数学推导**

### **A. 宏观信息约束的原理与金融意义**

宏观因素（如利率、货币政策）是驱动市场的重要低频变量。然而，由于宏观数据频率低且与高频交易数据的量纲和变动规律差异巨大，将其直接融入传统深度学习模型非常困难 1。

PINN（Physics-Informed Neural Network）提供了一种优雅的解决方案：它不直接将宏观变量作为输入特征，而是将宏观经济学中关于状态变量演化的理论或经验规律转化为微分方程（ODE/PDE），作为模型的结构性约束 1。模型通过PINN确保其内部对宏观状态的表示 $Z\_{NN}$ 必须遵守这些“物理定律”，从而实现了宏观信息对微观因子预测的“自上而下”指导 1。

### **B. 宏观状态方程的假设与建模**

原报告指出，宏观状态方程是从货币状态以及利率调节状态等角度构建的，涉及宏观状态的虚拟变量 $Z(t)$ 1。 $Z(t)$ 可以被视为代表市场流动性或风险溢价的隐变量。

#### **1\. 宏观状态方程的推测形式**

假设 $R(t)$ 代表政策利率（如短期LPR或逆回购利率），$T(t)$ 代表社会融资需求（如社融规模存量增速）。我们推导一个简化的宏观状态演化ODE，其中 $Z(t)$ 的变化率受其自身水平、利率水平和融资需求的影响：

$$\\mathcal{R}(Z, R, T) \\equiv \\frac{\\partial Z}{\\partial t} \- (\\beta\_0 Z(t) \+ \\beta\_1 R(t) \+ \\beta\_2 T(t) \\cdot Z(t)) \= 0$$  
其中，$\\beta\_0, \\beta\_1, \\beta\_2$ 是可学习的系数，$\\frac{\\partial Z}{\\partial t}$ 代表 $Z(t)$ 的时间导数。在复现时，需要一个小型神经网络 $\\mathcal{N}\_{PINN}$ 来拟合 $Z(t)$ 的值 $Z\_{NN}(t)$。

### **C. PINN损失函数 $\\mathcal{L}\_{PINN}$ 的构造**

宏观经济约束是通过引入**宏观状态损失约束**来实现的，这正是PINN损失函数中的物理损失项 $\\mathcal{L}\_{PINN}$ 1。

物理损失项 $\\mathcal{L}\_{PINN}$ 即是上述微分方程残差的L2范数，用于衡量神经网络 $Z\_{NN}$ 对宏观状态方程 $\\mathcal{R}$ 的满足程度：

$$\\mathcal{L}\_{PINN} \= \\frac{1}{T\_{macro}} \\sum\_{t=1}^{T\_{macro}} \\left| \\mathcal{R}(Z\_{NN}(t), R(t), T(t)) \\right|^2$$  
其中 $T\_{macro}$ 是用于约束的时间点数量。要计算 $\\frac{\\partial Z\_{NN}}{\\partial t}$，模型必须依赖深度学习框架（如PyTorch或TensorFlow）提供的自动微分（Autodiff）功能。PINN机制的有效性确保了宏观特征不仅能够被学习，而且其演化规律必须符合预设的经济学理论结构。

## **V. 双流网络融合与收益率解码机制的精确猜想**

### **A. 最终特征融合层的设计与结构**

PINN-MTICG模型是一个**时序截面双流网络模型**，它将三种模态的特征整合起来：$\\mathbf{F}\_{TS}$（时序，来自Multi-Transformer）、$\\mathbf{F}\_{CS}$（截面，来自indcap-GAT）以及 $\\mathbf{F}\_{Macro}$（宏观约束信息，来自 $\\mathcal{N}\_{PINN}$）1。

最常见的、且能支持高性能的特征融合结构涉及以下两个步骤：

1. **微观/中观特征整合：** 首先将Transformer和GAT的输出进行拼接，并通过一个多层感知机（MLP）学习交互项。  
   $$\\mathbf{F}\_{TC} \= \\text{MLP}\_{1}(\\text{Concat}(\\mathbf{F}\_{TS}, \\mathbf{F}\_{CS}))$$  
2. **宏观校准：** 随后，将宏观约束信息 $\\mathbf{F}\_{Macro}$ （即 $Z\_{NN}(t)$ 或从 $\\mathcal{N}\_{PINN}$ 提取的特征向量）引入，进行最终的特征融合。  
   $$\\mathbf{F}\_{Combined} \= \\text{MLP}\_{2}(\\text{Concat}(\\mathbf{F}\_{TC}, \\mathbf{F}\_{Macro}))$$

这种特征拼接后接MLP的结构允许网络学习非线性的交互项。例如，它可以学习到“当宏观流动性 $Z\_{NN}$ 处于低位时，市场关联性 $\\mathbf{F}\_{CS}$ 的影响会变得不那么重要，而个股自身的时序动量 $\\mathbf{F}\_{TS}$ 的影响可能增强”。这种层次化的信息流整合对于提高预测精度和鲁棒性至关重要。

### **B. 收益率解码机制：因子值回归**

模型的最终目标是产生一个用于选股的因子得分，该得分需与未来收益率具有高相关性（高IC）。尽管原报告未明确说明解码方式 1，但鉴于选股模型通常需要一个可排序的连续因子值，最可能且最稳健的解码器结构是使用一个简单的**线性层**（全连接层）进行回归：

$$\\hat{R}\_{i, t+T} \= \\mathbf{W}\_{output} \\cdot \\mathbf{F}\_{Combined, i} \+ b\_{output}$$  
其中 $\\hat{R}\_{i, t+T}$ 是股票 $i$ 在 $t$ 时刻对未来 $T$ 期收益率的预测值，即模型的因子得分（Factor Score）。报告中高达11.41%的月平均IC 1 强烈支持了该得分与真实未来收益率之间存在高度正相关性。

### **C. 综合损失函数的全景图：权重与平衡**

PINN-MTICG的训练是一个多任务优化过程，综合损失函数 $\\mathcal{L}\_{Total}$ 必须平衡预测准确性和宏观约束的遵守程度。

$$\\mathcal{L}\_{Total} \= \\mathcal{L}\_{Prediction} \+ \\lambda\_{PINN} \\mathcal{L}\_{PINN} \+ \\lambda\_{Reg} \\mathcal{L}\_{Regularization}$$

| 损失项 | 符号 | 数学形式 (推导) | 功能与重要性 |
| :---- | :---- | :---- | :---- |
| 预测损失 (MSE) | $\\mathcal{L}\_{Prediction}$ | $$\\frac{1}{N} \\sum\_{i=1}^{N} (R\_{i, t+T} \- \\hat{R}\_{i, t+T})^2$$ | 驱动因子得分 $\\hat{R}$ 与真实收益率 $R$ 拟合。 |
| 物理损失 (PINN) | $\\mathcal{L}\_{PINN}$ | $$\\frac{1}{T} \\sum\_{t=1}^{T} \\left | \\mathcal{R}(Z\_{NN}(t), R(t), T(t)) \\right |
| 正则化损失 | $\\mathcal{L}\_{Reg}$ | $$\\sum\_{W} |  |
| 总损失 | $\\mathcal{L}\_{Total}$ | $$\\mathcal{L}\_{Prediction} \+ \\lambda\_{PINN} \\mathcal{L}\_{PINN} \+ \\lambda\_{Reg} \\mathcal{L}\_{Reg}$$ | 整体优化目标。 |

**预测损失 ($\\mathcal{L}\_{Prediction}$) 的选择：** 尽管均方误差（MSE）是最稳定的选择，但考虑到金融选股的核心是排序而非绝对值预测，研究人员很可能使用了**排名损失（Rank Loss）**，例如Pairwise Ranking Loss或定制的IC Loss，以直接优化股票排序性能。在复现时，建议首先使用标准的 $\\mathcal{L}\_{MSE}$ 以确保训练稳定，并同时密切监控IC性能指标。

**权重平衡 ($\\lambda\_{PINN}$)：** 宏观约束权重 $\\lambda\_{PINN}$ 的选择是模型成功的关键。如果 $\\lambda\_{PINN}$ 过高，模型可能过度关注宏观理论，牺牲微观特征的学习；如果过低，则宏观约束形同虚设。一种常见的优化策略是，在预测损失 $\\mathcal{L}\_{Prediction}$ 达到一定收敛后，再逐步增加 $\\lambda\_{PINN}$，以确保宏观约束是在强大的微观因子基础之上进行校准。

## **VI. 模型高保真复现方案：技术栈与组件映射**

高保真复现PINN-MTICG模型需要一个能够高效处理时间序列（Transformer）、图结构（GAT）和微分方程约束（PINN）的集成技术栈。

### **A. 数据准备与预处理规范**

1. **时间窗口确定：** 模型的历史输入窗口 $T\_{history}$ 必须至少大于80日，才能支撑最长尺度的Transformer计算 1。预测周期 $T\_{lookahead}$ 通常对应于因子考核期（如未来5日或20日收益率）。  
2. **图结构处理：** GAT要求图结构 $\\mathcal{G}\_t$ 随时间 $t$ 动态变化。复现方案必须建立高效的图存储和加载机制。每日的行业关联图和资金流向图的邻接矩阵需要被计算和存储。  
3. **宏观数据：** 宏观状态方程所需的输入变量（如利率、M2、社融）需要进行严格的时间对齐和插值处理，以匹配高频的股票交易日。

### **B. 深度学习框架选型与库集成**

为了高效地实现多模态的深度学习模型，推荐使用以下技术栈：

* **核心框架：** PyTorch。PyTorch提供了动态图机制和强大的自定义模块能力，适合实现复杂的双流网络和门控融合层。  
* **图处理：** PyTorch Geometric (PyG)。PyG提供了高度优化的GATConv实现，能够高效处理每日更新的金融图结构。  
* **PINN模块：** 由于PINN需要对神经网络输出进行求导，建议使用专业的PINN库，如 DeepXDE，或参照开源项目 4 自定义实现 $\\mathcal{L}\_{PINN}$ 的计算逻辑。

### **C. 开源组件映射与代码基础**

在复现过程中，可以借鉴已有的金融Transformer和通用PINN框架，以加速开发并确保组件的专业性。

Table 3: PINN-MTICG模型核心组件与技术映射

| 模型组件 | 功能描述 | 建议实现库/框架 | 参考开源项目/片段 ID |
| :---- | :---- | :---- | :---- |
| 时序编码器 (Multi-Transformer) | 多尺度时间特征提取 | PyTorch Transformer Encoder | MASTER 6, SSPT 7 |
| 图结构编码器 (GAT) | 截面风险传导建模 | PyTorch Geometric (PyG) 的 GATConv | 通用GNN实现 |
| 宏观约束 (PINN Loss) | 引入物理损失项 | DeepXDE / 自定义 PyTorch Module | PINNs 5, Physics-Informed-NN 4 |
| 门控融合层 | 尺度信息聚合 | 自定义 PyTorch Module (MLP with Sigmoid/Softmax) | \- |

例如，MASTER 6 和 Stock Specialized Pre-trained Transformer (SSPT) 7 等项目提供了针对股票市场时间序列数据定制的Transformer架构，它们对位置编码和时间序列预处理的经验可以作为 Multi-Transformer 组件实现的基础。

### **D. 训练与优化策略**

成功的复现需要仔细调整关键的超参数和损失函数权重。

* **超参数重点：** 关注 Transformer 的层数（通常为2到4层）、GAT 的注意力头数（通常为4到8头），以及特征维度 $d\_{model}$。  
* **损失权重调整：** 必须系统性地搜索最优的 $\\lambda\_{PINN}$ 值。如前所述，初始训练阶段应重点优化 $\\mathcal{L}\_{Prediction}$，在模型开始收敛后，再逐渐引入和增加 $\\lambda\_{PINN}$，以实现宏观约束对微观因子的有效校准。  
* **性能对标：** 复现结果必须与原报告的关键性能指标进行严格对齐 1。

Table 4: PINN-MTICG关键性能指标对照与复现目标

| 性能指标 | PINN-MTICG (原报告数据) | 复现意义与目标 |
| :---- | :---- | :---- |
| 因子月平均IC | 11.41% | 衡量模型的因子区分度，目标是达到或超过此水平。 |
| 多头组合年化收益 | 37.51% | 衡量策略的绝对收益能力和alpha捕获能力。 |
| 月平均单边换手率 | 0.83X | 衡量交易成本，复现方案需确保在保持高收益的同时，换手率可控。 |
| CSI 300 指数增强超额收益 | 13.22% | 衡量模型相对于基准的超额alpha提取能力。 |

## **VII. 总结与应用前景**

PINN-MTICG模型成功地整合了时序、截面和宏观信息，构建了一个结构先进且性能卓越的选股框架。其核心优势在于：

1. **鲁棒的时序特征提取：** Multi-Transformer的多尺度设计有效捕捉了金融时间序列不同频率的信号，提高了特征对市场非平稳性的抵抗力。  
2. **动态的截面关联建模：** indcap-GAT利用行业和资金流双图结构，动态解析股票间的风险传导和共振效应，为个股预测提供了中观背景信息。  
3. **创新的宏观约束机制：** 通过引入PINN物理损失项，将低频的宏观经济演化规律作为软约束，解决了宏观因子难以与高频深度学习模型融合的难题，增强了模型在宏观环境变化时的稳健性和可解释性。

**复现挑战：** 尽管模型架构清晰，但宏观状态方程的具体数学定义和 $\\lambda\_{PINN}$ 这一关键损失权重系数的最佳选取是复现的核心难点。研究人员必须投入资源进行系统性的超参数搜索和经济理论的数学建模。

**未来展望：** 考虑到Transformer和GAT都存在过平滑问题 3，未来的工作可以探索将 SignGT 3 等机制应用于GAT或Transformer的注意力层，以减轻信息退化，从而进一步优化PINN-MTICG模型的深度和表达能力。通过高保真复现本模型，量化研究团队可以获得一个在不同市场条件下均表现出强大 alpha 提取能力的因子挖掘工具。

#### **引用的著作**

1. 20250407-西南证券-西南证券机器学习应用系列\_PINN信息约束与时序截面双流网络选股模型.md  
2. 基于多种Transformer架构的股票价格预测模型研究, 访问时间为 十一月 17, 2025， [https://pdf.hanspub.org/airr\_2610610.pdf](https://pdf.hanspub.org/airr_2610610.pdf)  
3. A Survey of Graph Transformers: Architectures, Theories and Applications \- arXiv, 访问时间为 十一月 17, 2025， [https://arxiv.org/html/2502.16533v2](https://arxiv.org/html/2502.16533v2)  
4. omniscientoctopus/Physics-Informed-Neural-Networks: Investigating PINNs \- GitHub, 访问时间为 十一月 17, 2025， [https://github.com/omniscientoctopus/Physics-Informed-Neural-Networks](https://github.com/omniscientoctopus/Physics-Informed-Neural-Networks)  
5. maziarraissi/PINNs: Physics Informed Deep Learning: Data-driven Solutions and Discovery of Nonlinear Partial Differential Equations \- GitHub, 访问时间为 十一月 17, 2025， [https://github.com/maziarraissi/PINNs](https://github.com/maziarraissi/PINNs)  
6. SJTU-DMTai/MASTER: This is the official code and supplementary materials for our AAAI-2024 paper: MASTER: Market-Guided Stock Transformer for Stock Price Forecasting. MASTER is a stock transformer for stock price forecasting, which models the momentary and cross-time stock correlation and guide feature selection with market information. \- GitHub, 访问时间为 十一月 17, 2025， [https://github.com/SJTU-DMTai/MASTER](https://github.com/SJTU-DMTai/MASTER)  
7. Pre-training Time Series Models with Stock Data Customization \- Hugging Face, 访问时间为 十一月 17, 2025， [https://huggingface.co/papers/2506.16746](https://huggingface.co/papers/2506.16746)