# GATè¾“å‡ºåˆ°äº”åˆ†ç±»çš„è½¬æ¢æœºåˆ¶è¯¦è§£

## ğŸ¯ ä¸€ã€æ•´ä½“æµç¨‹æ¦‚è¿°

ä»GATè¾“å‡ºåˆ°æœ€ç»ˆäº”åˆ†ç±»é¢„æµ‹çš„å®Œæ•´æµç¨‹ï¼š

```
æ—¶é—´ç‰¹å¾æå– â†’ å‹ç¼© â†’ GATå¤„ç† â†’ é¢„æµ‹å¤´(MLP) â†’ äº”åˆ†ç±»logits
[128ç»´]      [64ç»´]  [64ç»´]    [32ç»´â†’5ç»´]    [5ç»´]
```

## ğŸ“Š äºŒã€GATè¾“å‡ºç‰¹å¾

### 2.1 GATçš„è¾“å‡ºç»´åº¦

æ ¹æ®é…ç½®æ–‡ä»¶ `config/default_config.yaml`ï¼š

```yaml
gat:
  hidden_features: 128
  out_features: 64      # â­ GATæœ€ç»ˆè¾“å‡ºç»´åº¦
  num_heads: 8
  num_layers: 2
```

**GATè¾“å‡º**ï¼š
- å½¢çŠ¶ï¼š`[batch_size, gat_output_dim]` = `[batch_size, 64]`
- å«ä¹‰ï¼šèåˆäº†è¡Œä¸šå…³ç³»ä¿¡æ¯çš„èŠ‚ç‚¹ç‰¹å¾å‘é‡

### 2.2 GATå¤„ç†æµç¨‹

åœ¨ `components/model.py` ä¸­ï¼ˆç¬¬172-183è¡Œï¼‰ï¼š

```python
# 5. GATå¤„ç† - å­å›¾é‡‡æ ·æ¨¡å¼
if adj_matrix is not None and industry_indices is not None:
    # æå–å­å›¾: batchä¸­çš„è¡Œä¸š + å®ƒä»¬çš„1è·³é‚»å±…
    batch_gat_features = self._process_subgraph(
        compressed_features,      # [batch_size, 64]
        industry_indices,
        adj_matrix
    )
else:
    # å¦‚æœæ²¡æœ‰æä¾›é‚»æ¥çŸ©é˜µï¼Œä½¿ç”¨å¤‡ç”¨MLP
    batch_gat_features = self.fallback_mlp(compressed_features)

# batch_gat_features: [batch_size, 64]
```

**GATçš„ä½œç”¨**ï¼š
- âœ… èåˆè¡Œä¸šé—´çš„å…³è”ä¿¡æ¯
- âœ… é€šè¿‡å›¾æ³¨æ„åŠ›æœºåˆ¶ï¼Œè®©æ¯ä¸ªè¡Œä¸šèŠ‚ç‚¹èšåˆé‚»å±…èŠ‚ç‚¹çš„ç‰¹å¾
- âœ… è¾“å‡º64ç»´çš„è¡Œä¸šç‰¹å¾å‘é‡

## ğŸ”€ ä¸‰ã€é¢„æµ‹å¤´ï¼ˆPredictorï¼‰ç½‘ç»œç»“æ„

### 3.1 é¢„æµ‹å¤´å®šä¹‰

åœ¨ `components/model.py` ä¸­ï¼ˆç¬¬116-123è¡Œï¼‰ï¼š

```python
# é¢„æµ‹å¤´ï¼ˆ5åˆ†ä½æ•°åˆ†ç±»ï¼‰
# æ³¨æ„:ç§»é™¤Softmax,å› ä¸ºCrossEntropyLosså·²åŒ…å«LogSoftmax
self.predictor = nn.Sequential(
    nn.Linear(gat_output_dim, gat_output_dim // 2),  # 64 â†’ 32
    nn.ReLU(),
    nn.Dropout(dropout),
    nn.Linear(gat_output_dim // 2, num_classes)       # 32 â†’ 5
)
```

### 3.2 ç½‘ç»œç»“æ„è¯¦è§£

**é¢„æµ‹å¤´æ˜¯ä¸€ä¸ªä¸¤å±‚å‰é¦ˆç¥ç»ç½‘ç»œï¼ˆMLPï¼‰**ï¼š

```
è¾“å…¥: [batch_size, 64]  (GATè¾“å‡º)
  â†“
Linear(64 â†’ 32)
  â†“
ReLUæ¿€æ´»
  â†“
Dropout(0.1)
  â†“
Linear(32 â†’ 5)
  â†“
è¾“å‡º: [batch_size, 5]  (5ä¸ªç±»åˆ«çš„logits)
```

### 3.3 å„å±‚è¯¦ç»†è¯´æ˜

#### ç¬¬ä¸€å±‚ï¼šé™ç»´å±‚
```python
nn.Linear(gat_output_dim, gat_output_dim // 2)
# Linear(64, 32)
```
- **ä½œç”¨**ï¼šå°†64ç»´ç‰¹å¾å‹ç¼©åˆ°32ç»´
- **å‚æ•°é‡**ï¼š64 Ã— 32 + 32 = 2,080ä¸ªå‚æ•°
- **ç›®çš„**ï¼šå‡å°‘å‚æ•°é‡ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆï¼Œæå–å…³é”®ç‰¹å¾

#### æ¿€æ´»å‡½æ•°ï¼šReLU
```python
nn.ReLU()
```
- **ä½œç”¨**ï¼šå¼•å…¥éçº¿æ€§ï¼Œå¢å¼ºæ¨¡å‹è¡¨è¾¾èƒ½åŠ›
- **å…¬å¼**ï¼š`ReLU(x) = max(0, x)`

#### Dropoutå±‚
```python
nn.Dropout(dropout)  # dropout=0.1
```
- **ä½œç”¨**ï¼šè®­ç»ƒæ—¶éšæœºä¸¢å¼ƒ10%çš„ç¥ç»å…ƒï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ
- **æµ‹è¯•æ—¶**ï¼šæ‰€æœ‰ç¥ç»å…ƒéƒ½å‚ä¸è®¡ç®—ï¼ˆè‡ªåŠ¨å¤„ç†ï¼‰

#### ç¬¬äºŒå±‚ï¼šåˆ†ç±»å±‚
```python
nn.Linear(gat_output_dim // 2, num_classes)
# Linear(32, 5)
```
- **ä½œç”¨**ï¼šå°†32ç»´ç‰¹å¾æ˜ å°„åˆ°5ä¸ªç±»åˆ«çš„logits
- **å‚æ•°é‡**ï¼š32 Ã— 5 + 5 = 165ä¸ªå‚æ•°
- **è¾“å‡º**ï¼š5ä¸ªç±»åˆ«çš„æœªå½’ä¸€åŒ–åˆ†æ•°ï¼ˆlogitsï¼‰

## ğŸ“ˆ å››ã€å®Œæ•´å‰å‘ä¼ æ’­æµç¨‹

### 4.1 ä»GATåˆ°é¢„æµ‹çš„å®Œæ•´ä»£ç 

åœ¨ `components/model.py` çš„ `forward()` æ–¹æ³•ä¸­ï¼ˆç¬¬185-186è¡Œï¼‰ï¼š

```python
# 6. é¢„æµ‹
predictions = self.predictor(batch_gat_features)  # [batch_size, num_classes]
# predictions: [batch_size, 5]

return predictions, batch_gat_features
```

### 4.2 æ•°æ®æµå¯è§†åŒ–

```
GATè¾“å‡º:
batch_gat_features: [batch_size, 64]
  â†“
ç¬¬ä¸€å±‚Linear:
Linear(64 â†’ 32)
  â†“
hidden_features: [batch_size, 32]
  â†“
ReLUæ¿€æ´»:
ReLU(hidden_features)
  â†“
Dropout(è®­ç»ƒæ—¶):
Dropout(0.1)
  â†“
ç¬¬äºŒå±‚Linear:
Linear(32 â†’ 5)
  â†“
predictions: [batch_size, 5]  (logitsï¼Œæœªå½’ä¸€åŒ–)
```

### 4.3 å…·ä½“æ•°å€¼ç¤ºä¾‹

å‡è®¾ `batch_size=32`ï¼š

```python
# è¾“å…¥
batch_gat_features = torch.randn(32, 64)  # [32, 64]

# ç¬¬ä¸€å±‚
hidden = Linear(64, 32)(batch_gat_features)  # [32, 32]
hidden = ReLU(hidden)                        # [32, 32]
hidden = Dropout(0.1)(hidden)                # [32, 32] (è®­ç»ƒæ—¶)

# ç¬¬äºŒå±‚
predictions = Linear(32, 5)(hidden)          # [32, 5]

# predictionsç¤ºä¾‹:
# tensor([[ 0.5, -0.3,  1.2, -0.8,  0.1],   # æ ·æœ¬1çš„5ä¸ªç±»åˆ«logits
#         [-0.2,  0.8, -0.5,  1.1, -0.3],   # æ ·æœ¬2çš„5ä¸ªç±»åˆ«logits
#         ...])
```

## ğŸ¯ äº”ã€ä¸ºä»€ä¹ˆæ²¡æœ‰Softmaxï¼Ÿ

### 5.1 ä»£ç æ³¨é‡Šè¯´æ˜

åœ¨ `components/model.py` ç¬¬117è¡Œæœ‰æ³¨é‡Šï¼š

```python
# æ³¨æ„:ç§»é™¤Softmax,å› ä¸ºCrossEntropyLosså·²åŒ…å«LogSoftmax
```

### 5.2 åŸå› è§£é‡Š

**PyTorchçš„CrossEntropyLosså†…éƒ¨å®ç°**ï¼š
```python
# CrossEntropyLoss = LogSoftmax + NLLLoss
loss = nn.CrossEntropyLoss()
# å†…éƒ¨ä¼šè‡ªåŠ¨å¯¹è¾“å…¥åº”ç”¨LogSoftmaxï¼Œç„¶åè®¡ç®—è´Ÿå¯¹æ•°ä¼¼ç„¶
```

**å¦‚æœæ‰‹åŠ¨æ·»åŠ Softmax**ï¼š
```python
# âŒ é”™è¯¯åšæ³•
predictions = F.softmax(logits, dim=1)
loss = criterion(predictions, targets)
# ä¼šå¯¼è‡´æ•°å€¼ä¸ç¨³å®šï¼ˆdouble softmaxï¼‰
```

**æ­£ç¡®åšæ³•**ï¼š
```python
# âœ… æ­£ç¡®åšæ³•
predictions = self.predictor(batch_gat_features)  # ç›´æ¥è¾“å‡ºlogits
loss = self.criterion(predictions, targets)      # CrossEntropyLosså†…éƒ¨å¤„ç†
```

### 5.3 é¢„æµ‹æ—¶çš„å¤„ç†

åœ¨æ¨ç†æ—¶ï¼Œå¦‚æœéœ€è¦æ¦‚ç‡åˆ†å¸ƒï¼Œå¯ä»¥æ‰‹åŠ¨åº”ç”¨Softmaxï¼š

```python
# æ¨ç†æ—¶
model.eval()
with torch.no_grad():
    logits = model(...)  # [batch_size, 5]
    probs = F.softmax(logits, dim=1)  # [batch_size, 5]ï¼Œæ¦‚ç‡åˆ†å¸ƒ
    pred_class = logits.argmax(dim=1)  # [batch_size]ï¼Œé¢„æµ‹ç±»åˆ«
```

## ğŸ” å…­ã€é¢„æµ‹å¤´çš„è®¾è®¡é€‰æ‹©

### 6.1 ä¸ºä»€ä¹ˆä½¿ç”¨ä¸¤å±‚MLPï¼Ÿ

**ä¼˜ç‚¹**ï¼š
- âœ… **éçº¿æ€§æ˜ å°„**ï¼šReLUå¼•å…¥éçº¿æ€§ï¼Œå¢å¼ºè¡¨è¾¾èƒ½åŠ›
- âœ… **é™ç»´**ï¼š64â†’32â†’5ï¼Œé€æ­¥é™ç»´ï¼Œæå–å…³é”®ç‰¹å¾
- âœ… **é˜²æ­¢è¿‡æ‹Ÿåˆ**ï¼šDropoutå’Œé™ç»´éƒ½æœ‰æ­£åˆ™åŒ–æ•ˆæœ
- âœ… **å‚æ•°é‡é€‚ä¸­**ï¼šæ€»å‚æ•°é‡çº¦2,245ä¸ªï¼Œä¸ä¼šè¿‡å¤§

**ä¸ºä»€ä¹ˆä¸ä½¿ç”¨å•å±‚ï¼Ÿ**
- âŒ å•å±‚Linear(64â†’5)ï¼šè¡¨è¾¾èƒ½åŠ›æœ‰é™ï¼Œå¯èƒ½æ— æ³•å……åˆ†æå–ç‰¹å¾
- âŒ å‚æ•°é‡ï¼š64Ã—5+5=325ï¼Œè™½ç„¶æ›´å°‘ï¼Œä½†è¡¨è¾¾èƒ½åŠ›ä¸è¶³

**ä¸ºä»€ä¹ˆä¸ä½¿ç”¨ä¸‰å±‚æˆ–æ›´å¤šï¼Ÿ**
- âŒ å‚æ•°é‡å¢åŠ ï¼šå¯èƒ½å¯¼è‡´è¿‡æ‹Ÿåˆ
- âŒ å¯¹äº5åˆ†ç±»ä»»åŠ¡ï¼Œä¸¤å±‚å·²ç»è¶³å¤Ÿ

### 6.2 ç»´åº¦é€‰æ‹©çš„åŸå› 

**ç¬¬ä¸€å±‚ï¼š64 â†’ 32**
- é™ç»´ä¸€åŠï¼Œä¿ç•™ä¸»è¦ç‰¹å¾
- 32ç»´æ˜¯64å’Œ5çš„ä¸­é—´å€¼ï¼Œå¹³è¡¡è¡¨è¾¾èƒ½åŠ›å’Œå‚æ•°é‡

**ç¬¬äºŒå±‚ï¼š32 â†’ 5**
- ç›´æ¥æ˜ å°„åˆ°ç±»åˆ«æ•°
- 5ä¸ªè¾“å‡ºå¯¹åº”5ä¸ªåˆ†ä½æ•°ç±»åˆ«ï¼ˆ0-4ï¼‰

### 6.3 Dropoutçš„ä½œç”¨

```python
nn.Dropout(0.1)  # 10%çš„dropoutç‡
```

**ä½œç”¨**ï¼š
- âœ… **æ­£åˆ™åŒ–**ï¼šè®­ç»ƒæ—¶éšæœºä¸¢å¼ƒ10%çš„ç¥ç»å…ƒï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ
- âœ… **æé«˜æ³›åŒ–èƒ½åŠ›**ï¼šè®©æ¨¡å‹ä¸è¿‡åº¦ä¾èµ–æŸäº›ç‰¹å¾
- âœ… **æµ‹è¯•æ—¶è‡ªåŠ¨å…³é—­**ï¼š`model.eval()`æ—¶è‡ªåŠ¨ç¦ç”¨dropout

## ğŸ“ ä¸ƒã€å®Œæ•´ä»£ç ä½ç½®

| åŠŸèƒ½ | æ–‡ä»¶ä½ç½® | å…³é”®ä»£ç è¡Œ |
|------|---------|-----------|
| é¢„æµ‹å¤´å®šä¹‰ | `components/model.py` | ç¬¬116-123è¡Œ |
| GATè¾“å‡ºå¤„ç† | `components/model.py` | ç¬¬172-186è¡Œ |
| å‰å‘ä¼ æ’­ | `components/model.py` | `forward()` æ–¹æ³• |
| æŸå¤±è®¡ç®— | `components/trainer.py` | `train_epoch()` ç¬¬188è¡Œ |
| é¢„æµ‹ç±»åˆ«è§£ç  | `components/trainer.py` | `train_epoch()` ç¬¬220è¡Œ |

## ğŸ“ å…«ã€æ€»ç»“

### 8.1 å…³é”®è¦ç‚¹

1. **GATè¾“å‡º**ï¼š64ç»´ç‰¹å¾å‘é‡ `[batch_size, 64]`
2. **é¢„æµ‹å¤´ç»“æ„**ï¼šä¸¤å±‚MLP
   - ç¬¬ä¸€å±‚ï¼šLinear(64â†’32) + ReLU + Dropout(0.1)
   - ç¬¬äºŒå±‚ï¼šLinear(32â†’5)
3. **è¾“å‡º**ï¼š5ä¸ªç±»åˆ«çš„logits `[batch_size, 5]`
4. **æ²¡æœ‰Softmax**ï¼šCrossEntropyLosså†…éƒ¨å·²åŒ…å«LogSoftmax

### 8.2 ç½‘ç»œå‚æ•°é‡

```
é¢„æµ‹å¤´æ€»å‚æ•°é‡ï¼š
- ç¬¬ä¸€å±‚ï¼š64 Ã— 32 + 32 = 2,080
- ç¬¬äºŒå±‚ï¼š32 Ã— 5 + 5 = 165
- æ€»è®¡ï¼š2,245ä¸ªå‚æ•°
```

### 8.3 è®¾è®¡ä¼˜åŠ¿

- âœ… **ç®€æ´é«˜æ•ˆ**ï¼šä¸¤å±‚MLPè¶³å¤Ÿå®Œæˆ5åˆ†ç±»ä»»åŠ¡
- âœ… **é˜²æ­¢è¿‡æ‹Ÿåˆ**ï¼šDropoutå’Œé™ç»´æä¾›æ­£åˆ™åŒ–
- âœ… **æ•°å€¼ç¨³å®š**ï¼šä¸æ‰‹åŠ¨æ·»åŠ Softmaxï¼Œç”±æŸå¤±å‡½æ•°å¤„ç†
- âœ… **æ˜“äºç†è§£**ï¼šç»“æ„ç®€å•ï¼Œä¾¿äºè°ƒè¯•å’Œä¼˜åŒ–

### 8.4 é¢„æµ‹æµç¨‹

```python
# è®­ç»ƒæ—¶
logits = model(...)                    # [batch_size, 5]
loss = CrossEntropyLoss(logits, targets)  # å†…éƒ¨åº”ç”¨LogSoftmax

# æ¨ç†æ—¶
logits = model(...)                    # [batch_size, 5]
pred_class = logits.argmax(dim=1)      # [batch_size]ï¼Œé¢„æµ‹ç±»åˆ«(0-4)
probs = F.softmax(logits, dim=1)       # [batch_size, 5]ï¼Œæ¦‚ç‡åˆ†å¸ƒï¼ˆå¯é€‰ï¼‰
```

**é¢„æµ‹ç±»åˆ«å«ä¹‰**ï¼š
- 0ï¼šæœ€ä½20%æ”¶ç›Šç‡ï¼ˆæœ€å·®ï¼‰
- 1ï¼š20-40%æ”¶ç›Šç‡
- 2ï¼š40-60%æ”¶ç›Šç‡ï¼ˆä¸­ç­‰ï¼‰
- 3ï¼š60-80%æ”¶ç›Šç‡
- 4ï¼šæœ€é«˜20%æ”¶ç›Šç‡ï¼ˆæœ€å¥½ï¼‰

